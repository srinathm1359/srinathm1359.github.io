<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Srinath Mahankali</title>

    <meta name="author" content="Srinath Mahankali">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:60%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Srinath Mahankali
                </p>
                <p> I am an undergraduate student at <a href="https://www.mit.edu/">MIT</a> where I am advised by <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> 
                    as part of the <a href="https://www.csail.mit.edu/">Computer Science and Artificial Intelligence Laboratory (CSAIL).</a> 
                    
                    I am very interested in deep learning, reinforcement learning, and their application to robotics.
                    Currently, I am working on improving exploration in deep reinforcement learning and developing 
                    energy-efficient controllers for quadruped locomotion through sim-to-real reinforcement learning.
                <p style="text-align:center">
                <p>
                    Previously, I worked on inverse problems with <a href="https://yunany.github.io/"> Yunan Yang</a> and studied the linear
                    separability of one-layer neural networks with <a href="https://sites.google.com/view/promit-ghosal/home?authuser=0"> Promit Ghosal.</a>
                </p>
                  <a href="mailto:srinathm@mit.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Mahankali_CV_Fall_2023.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=D9rT1Z0AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/srinath-mahankali-1a50b7200/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/srinath.jpg" class="hoverZoomLink">
              </td>
              <!-- <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:100%;max-width:100%" alt="profile photo" src="images/srinath.jpg">
              </td> -->
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h2>Updates</h2>
                <p>
                <table class="tab">
                  <tr>
                    <td><i>May '24 &emsp;</i></td>
                    <td>Our Random Latent Exploration paper was accepted to ICML '24! </td>
                  </tr>
                  <tr>
                    <td><i>Mar '24 &emsp;</i></td>
                    <td>Awarded the  <a href="https://goldwaterscholarship.gov/">Goldwater Scholarship!</a></td>
                  </tr>
                  <tr>
                    <td><i>Jan '24 &emsp;</i></td>
                    <td>Our Energy Efficient Locomotion paper was accepted to ICRA '24! </td>
                  </tr>
              </table>
              </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <!-- Paper title: Random Latent Exploration for Deep Reinforcement Learning-->
            <!-- Paper link: Coming soon! -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/rle_atari_performance.png" alt="sym" width="100%" style="border-radius:5px">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Random Latent Exploration for Deep Reinforcement Learning</span>
                  <br>
                  <strong>Srinath Mahankali</strong>, 
                  <a href="https://williamd4112.github.io/">Zhang-Wei Hong</a>,
                  <a href="https://ayush.sekhari.com/">Ayush Sekhari</a>,
                  <a href="https://www.mit.edu/~rakhlin/">Alexander Rakhlin</a>, 
                  <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> 
                  <br>
                  <em>ICML, 2024</em>
                  <br>
                  <br>
                  <a href="https://srinathm1359.github.io/random-latent-exploration/">project website</a>
                  <p> We improve exploration in both discrete and continuous control domains by optimizing random reward functions parameterized by a sampled latent vector.</p>
          </tr>

            <!-- Paper title: Maximizing Velocity by Minimizing Energy -->
            <!-- Paper link: Coming soon! -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/eipo_spin.gif" alt="sym" width="100%" style="border-radius:5px">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Maximizing Velocity by Minimizing Energy</span>
                    <br>
                    <strong>Srinath Mahankali*</strong>, 
                    <a href="https://dblp.org/pid/258/6861.html">Chi-Chang Lee*</a>,
                    <a href="https://gmargo11.github.io/">Gabriel B. Margolis</a>, 
                    <a href="https://williamd4112.github.io/">Zhang-Wei Hong</a>, 
                    <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> 
                    <br>
                    <em>ICRA, 2024</em>
                    <br>
                    <br>
                    <p> We train energy-efficient policies for quadruped locomotion tasks while improving task performance 
                        through constrained reinforcement learning.</p>
            </tr>
            
            <!-- Paper title: Is Random Reward All You Need?-->
            <!-- Paper link: Coming soon! -->
            <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/random_reward.png" alt="sym" width="100%" style="border-radius:5px">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Does Novelty-Based Exploration Maximize Novelty?</span>
                    <br>
                    <strong>Srinath Mahankali</strong>, 
                    <a href="https://williamd4112.github.io/">Zhang-Wei Hong</a>, 
                    <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> 
                    <br>
                    <em>Coming Soon!</em>
                    <br>
                    <br>
                    <p> Randomly generated rewards improve exploration by almost as much as state-of-the-art novelty-based intrinsic motivation.</p>
            </tr> -->

            <!-- Paper title: Norm-dependent convergence and stability of the inverse scattering series for diffuse and scalar waves -->
            <!-- Paper link: https://arxiv.org/abs/2208.07931 -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2208.07931.pdf">
                    <img src="images/inverse_scattering_labels.png" alt="sym" width="100%" style="border-radius:5px">
                    </a>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2208.07931.pdf">
                    <span class="papertitle">Norm-dependent convergence and stability of the inverse scattering series for diffuse and scalar waves</span>
                    </a>
                    <br>
                    <strong>Srinath Mahankali</strong>, 
                    <a href="https://yunany.github.io/">Yunan Yang</a>
                    <br>
                    <em>Inverse Problems</em>, 2023
                    <br>
                    <br>
                    <a href="https://arxiv.org/pdf/2208.07931.pdf">paper</a> /
                    <a href="https://arxiv.org/abs/2208.07931">abstract</a>
                    <p> We prove bounds on the convergence and stability of the inverse scattering series
                        under different Sobolev norms, finding conditions under which the radius of convergence
                        and stability are improved.
            </tr>

            <!-- Paper title: Randomly Initialized One-Layer Neural Networks Make Data Linearly Separable -->
            <!-- Paper link: https://arxiv.org/abs/2205.11716 -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2205.11716.pdf">
                    <img src="images/linear_separable.png" alt="sym" width="100%" style="border-radius:5px">
                    </a>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2205.11716.pdf">
                    <span class="papertitle">Randomly Initialized One-Layer Neural Networks Make Data Linearly Separable</span>
                    </a>
                    <br>
                    <a href="https://sites.google.com/view/promit-ghosal/home?authuser=0">Promit Ghosal</a>,
                    <strong>Srinath Mahankali</strong>, 
                    <a href="https://www.linkedin.com/in/kimiyihangsun">Yihang Sun</a>
                    <br>
                    <em>arXiv preprint</em>, 2022
                    <br>
                    <br>
                    <a href="https://arxiv.org/pdf/2205.11716.pdf">paper</a> /
                    <a href="https://arxiv.org/abs/2205.11716">abstract</a>
                    <p> Randomly initialized one-layer neural networks, with high probability, make datasets linearly separable. </p>
            </tr>

            <!-- Paper title: The convexity of optimal transport-based waveform inversion for certain structured velocity models-->
            <!-- Paper link: https://arxiv.org/abs/2009.00708 -->
            <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2009.00708.pdf">
                        <img src="images/obj_nonconvex.png" alt="sym" width="90%" style="border-radius:5px">
                    </a>
                    <a href="https://arxiv.org/pdf/2009.00708.pdf">
                        <img src="images/obj_convex.png" alt="sym" width="90%" style="border-radius:5px">
                    </a>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2009.00708.pdf">
                    <span class="papertitle">The convexity of optimal transport-based waveform inversion for certain structured velocity models</span>
                    </a>
                    <br>
                    <strong>Srinath Mahankali</strong>
                    <br>
                    <em>SIAM Undergraduate Research Online</em>, 2021
                    <br>
                    <br>
                    <a href="https://arxiv.org/pdf/2009.00708.pdf">paper</a> /
                    <a href="https://arxiv.org/abs/2009.00708">abstract</a>
                    <p> Full waveform inversion with an optimal transport-based objective has superior convexity 
                        compared to the standard least-squares objective function for certain
                        velocity models. </p>
                </td>
            </tr>

          </tbody></table>   
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                    Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website.</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>