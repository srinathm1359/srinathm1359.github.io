<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Title -->
    <title>Random Latent Exploration for Deep Reinforcement Learning</title>

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="rsc/green_dot.png">

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Random Latent Exploration for Deep Reinforcement Learning">
    <meta name="keywords" content="Exploration, Deep Reinforcement Learning">

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <!-- https://fontawesome.com/cheatsheet -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    

    <style>
        body, html {
            padding: 0;
            margin: 0;
            width: 100%;
            height: 100%;
        }
        .container {
            width: 90%;
            max-width: 100%;
            padding: 0;
            margin: 0 auto;
        }
        hr {
            border: none;
            height: 2px;
            /* Set the hr color */
            color: #000000;  /* old IE */
            background-color: #000000;  /* Modern Browsers */
        }
        .header-container {
            display: flex;
            flex-direction: row;
            justify-content: space-between;
            align-items: center;
            font-size: 20px;
            padding-top: 0px;
        }
        .header-text {
            text-align: center;
        }
        .parent-container {
            display: flex;
            justify-content: center;
            align-items: center;
            /* border: 5px solid black; */
            /* height: 100vh; */
        }
        .video-container {
            display: flex;
            justify-content: space-between;
            flex-wrap: wrap;
            width: 100%;
            gap: 1px;
        }

        /* Container for the three boxes */
        .card-container {
            display: flex;
            align-items: center;
            /* flex-direction: column; */
            justify-content: space-between; /* Even spacing between boxes */
            /* align-items: flex-start; */
            flex-wrap: nowrap; /* Ensures all boxes stay on one row */
            padding: 10px;
            background-color: #f5f5f5;
            box-sizing: border-box;
        }
        /* Styling each exploration strategy box */
        .strategy-box {
            background-color: white;
            padding: 10px;
            margin: 5px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.259);
            width: 300px;
            text-align: center;
            transition: transform 0.3s ease; /* Animation on hover */
        }
        .strategy-box:hover {
            transform: scale(1.05); /* Slightly enlarge on hover */
        }
        /* Title of each strategy */
        .strategy-box h3 {
            font-size: 1.5em;
            color: #333;
            margin-bottom: 15px;
        }
        /* Image styling inside each strategy box */
        .strategy-box img {
            width: 75%;
            height: auto;
            margin-bottom: 15px;
        }
        /* Description and text under the image */
        .strategy-box p {
            font-size: 1em;
            /* color: #666; */
            color: #000000;
            line-height: 1.4em;
            margin-bottom: 10px;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        /* Emphasizing text */
        .strategy-box .highlight {
            color: red;
            /* font-weight: bold; */
        }

        .video-container video {
            /* width: 33%; */
            height: auto;
            margin: 2px auto;
            border: 2px solid black;
            /* box-sizing: border-box; */
        }
        #main-video {
            /* padding-top: 10px; */
            /* font-size: 20px; */
            border: 2px solid black;
        }
        .arrow {
            font-size: 36px;
            margin: 10px 0;
        }
        .long-arrow {
            width: 2px;
            height: 50px; /* Adjust the height to make the arrow longer */
            background-color: #000;
            margin: 10px auto;
            position: relative;
        }

        .long-arrow::before {
            content: '';
            width: 0; 
            height: 0; 
            border-left: 10px solid transparent;
            border-right: 10px solid transparent;
            border-top: 10px solid #000;
            position: absolute;
            top: 50px; /* Position the arrowhead at the bottom */
            left: -8px; /* Center the arrowhead */
        }
    </style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-9MLNCESWHS"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9MLNCESWHS');
    </script>

</head>


<body>

    <!-- Video Function -->
    <script>
        function setVideoLoop(videoId, initialStartTime, startTime, endTime) {
            const video = document.getElementById(videoId);
    
            // initially set the start time to be the endtime so it loops from the completed slide
            // video.currentTime = endTime - 0.5;
            video.currentTime = initialStartTime;
            video.play();
    
            video.addEventListener('timeupdate', () => {
                if (video.currentTime >= endTime) {
                    video.currentTime = startTime;
                    video.play();
                }
            });
        }
    
        document.addEventListener('DOMContentLoaded', (event) => {
            // setVideoLoop('action noise', 14, 14, 23);
            // setVideoLoop('parameter noise', 24.5, 24.5, 33.5);
            // setVideoLoop('exploration bonus', 35, 35, 48);
            // setVideoLoop('formulation', 49, 49, 62.5);
            // setVideoLoop('implementation', 64.5, 72);
            // setVideoLoop('implementation', 71, 71, 72);
            // setVideoLoop('state space coverage', 74.5, 80);
            setVideoLoop('state space coverage', 77.5, 77.5, 80);
            // setVideoLoop('atari results', 82, 91);
            setVideoLoop('atari results', 90, 90, 91); // TODO
            // setVideoLoop('isaacgym results', 92, 100);
            setVideoLoop('isaacgym results', 99, 99, 100); // TODO
        });
      </script>

    <!-- <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"> -->
    <nav class="navbar navbar-expand-md fixed-top navbar-dark" style="background-color: #A31F34;">
        <a class="navbar-brand" href="#">Random Latent Exploration for Deep Reinforcement Learning</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggle">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarToggle">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="#">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Video">Video</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Abstract">Abstract</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Paper">Paper</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Overview">Overview</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Results">Results</a>
                </li>
            </ul>
        </div>
    </nav>
    <br>
    <div class="container" id="Title" style="padding-top: 80px; font-size: 20px">
        
        <div align="center">
            <h2 class="text-center" align="center">
              Random Latent Exploration for Deep Reinforcement Learning
            </h2>
            <h6>
                <a href="https://srinathm1359.github.io/">Srinath Mahankali</a>, 
                <a href="https://williamd4112.github.io/">Zhang-Wei Hong</a>,
                <a href="https://ayush.sekhari.com/">Ayush Sekhari</a>, 
                <a href="https://www.mit.edu/~rakhlin/">Alexander Rakhlin</a>, 
                <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> 
            </h6>
            <p style="padding : 0; margin : 0; line-height : 30px;"><small>Improbable AI Lab</small></p>
            <p style="padding : 0; margin : 0; line-height : 30px;"><small> Computer Science and Artificial Intelligence Laboratory (CSAIL)</small></p>
            <p style="padding : 0; margin : 0; line-height : 30px;"><small> Massachusetts Institute of Technology (MIT)</small></p>
            <p style="color: green; padding : 0; margin : 0; line-height : 30px;"><small>International Conference on Machine Learning (ICML), 2024</small></p>
            <div class="logo-container">
                <div>
                <object hspace="50">
                    <a href="https://www.csail.mit.edu/" target="_blank">
                        <img src="rsc/CSAIL_Primary_Regular_RGB.png" alt="MIT" width="100">
                    </a>
                </object>
                <object hspace="50">
                    <a href="https://people.csail.mit.edu/pulkitag/" target="_blank">
                        <img src="rsc/IAI_Logo.jpg" alt="Improbable AI" width="100">
                    </a>
                </object>
                </div>
            </div>
        </div>
        
    </div><br>

    <center>
        <button class="btn btn-blue" 
                onmouseover="this.style.backgroundColor='#0080ff'" 
                onmouseout="this.style.backgroundColor='#0066cc'" 
                style="display: inline-block; padding: 8px 16px 8px 42px; font-size: 16px; color: white; background-color: #0066cc; background-image: url(rsc/icons8-paperwork-32.png); background-repeat: no-repeat; background-position: left center; border: none; border-radius: 4px;" 
                onclick="window.location.href='https://arxiv.org/abs/2407.13755';"
                >
                Paper</button>
        <button class="btn" onmouseover="this.style.backgroundColor='#444'" onmouseout="this.style.backgroundColor='#333'" style="display: inline-block; padding: 8px 16px 8px 36px; font-size: 16px; color: white; background-color: #333; background-image: url(https://github.com/favicon.ico); background-repeat: no-repeat; background-position: left center; border: none; border-radius: 4px;" onclick="window.location.href='https://github.com/Improbable-AI/random-latent-exploration';">GitHub</button>
    </center><br>

    <!-- straight -->
    <div class="container" id="Main-Video" style="padding-top: 10px; font-size: 20px">
        <h2 id="Video" style="padding-top: 70px; margin-top: -80px; ">Video</h2>
        <hr>
        <div align="center">
            <div class="center" id="main-video-div" style="position: relative;">
                <video
                  width="100%"
                  style="max-width: 640px; display: block;"
                  id="main-video"
                  controls
                >
                  <!-- <source src="rsc/ASMP_Spotlight_Narrated.mp4" type="video/mp4" /> -->
                  <source src="rsc/RLE ICML 2024 Teaserv2 - Havanav2.mp4" type="video/mp4" />
                  <!-- <track src="rsc/ASMP_Spotlight_Narrated.vtt" kind="subtitles" srclang="en" label="English" default> -->
                </video>
                <!-- <div
                  id="playButton"
                  style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); cursor: pointer; background-color: #000000; border: none; color: #ffffff; padding: 10px 20px; font-size: 1.5em;"
                  onclick="playVideo()"
                >
                  â–¶
                </div> -->
              </div>

              <script>
                document.addEventListener('DOMContentLoaded', function () {
                  const video = document.getElementById('video');
                  const track = document.getElementById('track');
                  track.track.mode = 'showing'; // this will show the subtitles by default
                  video.play(); // start playing the video
                });
              </script>
              
              <script>
                function playVideo() {
                  const video = document.getElementById('video');
                  const playButton = document.getElementById('playButton');
                  const track = document.getElementById('track');
                  track.track.mode = 'showing'; // this will show the subtitles by default
                  video.play();
                  playButton.style.display = 'none';
                }
              
                document.getElementById('video').addEventListener('ended', function () {
                  const playButton = document.getElementById('playButton');
                  playButton.style.display = 'block';
                });
              </script>
            </div>
        </div>
    </div><br>

    <!-- Abstract -->
    <div class="container" id="Abstract">
        <h2 id="Abstract" style="padding-top: 70px; margin-top: -80px; ">Abstract</h2>
        <hr>
        <div style="text-align: left">
            Exploration is a longstanding challenge in reinforcement learning (RL), which is typically addressed through 
            either noise-based or bonus-based exploration strategies. Noise-based methods are easy to implement but 
            struggle with deep exploration, while bonus-based methods, though more complex, excel in tasks requiring 
            deep exploration. Since both approaches perform similarly on average, noise-based exploration is commonly 
            used in deep RL algorithms due to its simplicity. In this paper, we introduce Random Latent Exploration (RLE),
            a simple yet effective exploration strategy that outperforms both methods on average. The core idea is 
            to motivate the agent to explore different parts of the environment by pursuing randomly sampled goals. 
            The agent's policy is conditioned on randomly sampled vectors that serve as goals, and these vectors 
            provide varying rewards at each state, encouraging the agent to explore different areas of the environment.
            RLE is as simple as noise-based methods, as it avoids complex bonus calculations. Our experiments show 
            that RLE improves performance on average in both discrete (e.g., Atari) and continuous control tasks 
            (e.g., Isaac Gym), enhancing exploration while remaining a simple and general plug-in for existing RL 
            algorithms.
        </div>
    </div><br><br>

    <!-- Paper -->
    <div class="container">
        <h2 id="Paper" style="padding-top: 70px; margin-top: -80px;">Paper</h2>
        <hr>

        <div class="row">
            <div class="col-md-12">
                <b>Random Latent Exploration for Deep Reinforcement Learning</b><br>
                <a href="https://srinathm1359.github.io/">Srinath Mahankali</a>, 
                <a href="https://williamd4112.github.io/">Zhang-Wei Hong</a>,
                <a href="https://ayush.sekhari.com/">Ayush Sekhari</a>, 
                <a href="https://www.mit.edu/~rakhlin/">Alexander Rakhlin</a>, 
                <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> 
                <p><em>International Conference on
                    Machine Learning (ICML), 2024 </em></p>
                <a href="https://arxiv.org/abs/2407.13755" target="_blank">paper</a> /
                <a href="https://srinathm1359.github.io/random-latent-exploration" target="_blank">project page</a> /
                <a href="" data-toggle="modal" data-target="#icml24-bibtex">
                    bibtex
                </a>
            </div>

            <!-- Modal -->
            <div class="modal fade" id="icml24-bibtex" tabindex="-1" role="dialog" aria-labelledby="exampleModalCenterTitle" aria-hidden="true">
                <div class="modal-dialog modal-dialog-centered modal-lg" role="document">
                    <div class="modal-content">
                        <div class="modal-header">
                            <h5 class="modal-title" id="rss-bibtex-title">bibtex</h5>
                            <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                                <span aria-hidden="true">&times;</span>
                            </button>
                        </div>
                        <div class="modal-body">
    <pre>
    @article{mahankali2024random,
        title={Random Latent Exploration for Deep Reinforcement Learning},
        author={Mahankali, Srinath and Hong, Zhang-Wei and Sekhari, Ayush and Rakhlin, Alexander and Agrawal, Pulkit},
        journal={International Conference on Machine Learning},
        year={2024}
    }
    </pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <br><br>

    <div class="container">
        <h2 id="Overview" style="padding-top: 70px; margin-top: -80px;">Overview</h2>
        <hr>
            <h3 id="Motivation" style="padding-top: 70px; margin-top: -80px;">
            Generating diverse trajectories is hard with common exploration strategies
            </h3>
            <!-- Put the three slides: (1) Action noise, (2) Parameter noise, (3) Exploration bonus - they explain why they are bad -->
            
            <br>
            <!-- TODO: Replace these videos with 3 divs side by side with the same information -->
            <div class="parent-container">
                <div class="card-container" style="display: flex;">
                    <div class="strategy-box" style="width: 33%; text-align: center;">
                        <h4>Action Noise</h4>
                        <p>Perturb the policy's actions via random sampling</p>
                        <p>e.g., \(\varepsilon\)-greedy or entropy regularization</p>
                        <img src="rsc/expl_strategies_imgs/action_noise.png" alt="Action noise leads to similar trajectories in one training iteration.">
                        <!-- <p style="color: red;">The generated trajectories explore similar regions!</p> -->
                        <p class="highlight">The generated trajectories explore similar regions!</p>
                    </div>
                    <div class="strategy-box" style="width: 33%; text-align: center;">
                        <h4>Parameter Noise</h4>
                        <p>Perturb the policy's parameters randomly instead</p>
                        <p>Adds some diversity to generated trajectories!</p>
                        <img src="rsc/expl_strategies_imgs/parameter_noise.png" alt="Parameter noise leads to slightly more diverse trajectories, but still not enough.">
                        <p class="highlight">Does not yield enough diversity empirically!</p>
                    </div>
                    <div class="strategy-box" style="width: 33%; text-align: center;">
                        <h4>Exploration Bonus</h4>
                        <p>Relies on action noise for trajectory diversity</p>
                        <p>Rewards policy for visiting novel states</p>
                        <img src="rsc/expl_strategies_imgs/exploration_bonus.png" alt="Exploration bonus leads to diverse experience, but only over multiple training iterations.">
                        <p class="highlight">Needs multiple iterations to yield diverse trajectories!</p>
                    </div>
                </div>
            </div>

            <br>

            <h3 id="Method" style="padding-top: 70px; margin-top: -80px;">
            RLE formulation and implementation
            </h3>

            <!-- TODO: Replace the two videos with a single card indicating the formulation and implementation -->
            <div class="parent-container">
                <div class="card-container" style="display: flex;">
                    <div class="strategy-box" style="width: 50%; text-align: center; height: 25em;">
                        <h4>Our Method: Random Latent Exploration (RLE)</h4>
                        <!-- <p>Perturb the reward function randomly</p> -->
                        <!-- <p>Condition the policy on the perturbation</p> -->
                        <p>Perturb the reward randomly and condition the policy on the perturbation</p>
                        <img src="rsc/expl_strategies_imgs/random_latent_exploration.png" 
                        alt="Random Latent Exploration leads to diverse trajectories in one iteration."
                        style="width: 43.5%;">
                        <!-- <p class="highlight">Visit different regions of the environment with the same policy!</p> -->
                        <p class="highlight">Allows the same policy to visit different regions of the environment!</p>
                    </div>
                    <div class="strategy-box" style="width: 50%; text-align: center; height: 25em;">
                        <h2>RLE is Simple to Implement</h2>

                        <p style="line-height: 1.2em; font-size: 1.4em;">
                            Initialize feature network \(\phi\)
                        </p>
                        <div class="arrow">&#x21e9;</div>
                        <p style="line-height: 1.2em; font-size: 1.4em;">
                            Sample a random latent vector \(\textcolor{red}{\boldsymbol{z}}\)
                        </p>
                        <div class="arrow">&#x21e9;</div>
                        <p style="line-height: 1.2em; font-size: 1.4em;">
                            Perturb the reward function using \(\textcolor{red}{\boldsymbol{z}}\): 
                            \(r_{\mathrm{new}} = r_{\mathrm{task}} + \phi(s) \cdot \textcolor{red}{\boldsymbol{z}}\)
                        </p>
                        <div class="arrow">&#x21e9;</div>
                        <!-- <p style="line-height: 6em;">
                            Resample \(\boldsymbol{z}\) on episode termination or after a fixed number of time steps
                        </p> -->
                        <p style="line-height: 1.2em; font-size: 1.4em;">
                            Train policy \(\pi(s,\textcolor{red}{\boldsymbol{z}})\) using \(r_{\mathrm{new}}\)
                        </p>
                    </div>
                </div>
            </div>
            <br>

        <h2 id="Results" style="padding-top: 70px; margin-top: -80px;">Results</h2>
        <hr>

            <h3 id="Results" style="padding-top: 70px; margin-top: -80px;">
            Improved state space coverage with RLE
            </h3>

            <div class="parent-container">
            <div class="video-container" style="display: flex;">
            <video id="state space coverage" muted playsinline width="100%" style="max-width: 640px; display: block;">
                <source src="rsc/RLE ICML 2024 Teaserv2 - Havanav2.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            </div>
            <br>

            <h3 id="Results" style="padding-top: 70px; margin-top: -80px;">
            RLE improves in Atari (57 Tasks) and IsaacGym (9 Tasks)
            </h3>

            <div class="parent-container">
            <div class="video-container" style="display: flex;">
            <video id="atari results" muted playsinline width="49%" style="max-width: 640px; display: block;">
                <source src="rsc/RLE ICML 2024 Teaserv2 - Havanav2.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            <video id="isaacgym results" muted playsinline width="49%" style="max-width: 640px; display: block;">
                <source src="rsc/RLE ICML 2024 Teaserv2 - Havanav2.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
            </div>
            </div>

        <br>

    <br>      
    </div>
    
    
    <br><br>

    

    

    <div class="container" id="Author Contributions">
        <h2 id="author-contributions" style="padding-top: 30px; margin-top: -40px;">Author Contributions</h2>
        <hr>
        <!-- Do the same as above with decreased spacing vertically -->
        <!-- Do this by decreasing margin or padding -->
        <p style="margin-bottom: 0px;">
            <a href="https://srinathm1359.github.io/">Srinath Mahankali</a> ran initial experiments to investigate the benefit of random 
            rewards that informed the eventual formulation of RLE, which he then compared against baseline methods on Atari
            and IsaacGym environments and helped with paper writing.
        </p>
        <p style="margin-bottom: 0px;">
            <a href="https://williamd4112.github.io/">Zhang-Wei Hong</a> conceived the possibility of using random rewards
            for exploration. He was involved in research discussions, helped scale experiments, played a significant role
            in paper writing, and advised Srinath.
        </p>
        <p style="margin-bottom: 0px;">
            <a href="https://ayush.sekhari.com/">Ayush Sekhari</a> was involved in research discussions and helped set the
            overall formulation of RLE. He played a significant role in paper writing, and advised Srinath and Zhang-Wei.
        </p>
        <p style="margin-bottom: 0px;">
            <a href="https://www.mit.edu/~rakhlin/">Alexander Rakhlin</a> was involved in research discussions and advising.
        </p>
        <p style="margin-bottom: 0px;">
            <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> was involved in research discussions, 
            overall advising, paper writing, and positioning of the work.
        </p>

    </div>
        

    <br><br>

    <center>
    <p>Website made using <a href="https://taochenshh.github.io/projects/visual-dexterity">this template</a>.</p>
    </center>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

</body>

</html>